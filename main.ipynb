{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy\n",
    "# torch.__version__ #2.6.0+cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__) #2.6.0+cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device  cuda\n",
      "['sm_50', 'sm_60', 'sm_61', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90']\n",
      "['c:\\\\Users\\\\Joshua\\\\anaconda3\\\\envs\\\\MLI\\\\Lib\\\\site-packages\\\\torch']\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "print(\"device \", device)\n",
    "print(torch.cuda.get_arch_list())\n",
    "print(torch.__path__)\n",
    "# TODO: Activate GPU\n",
    "#If GPU is found (correct version of torch is found), then the following will be printed:\n",
    "\n",
    "# True\n",
    "# device  cuda\n",
    "# ['sm_50', 'sm_60', 'sm_61', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90']\n",
    "# ['c:\\\\Users\\\\Joshua\\\\anaconda3\\\\envs\\\\MLI\\\\Lib\\\\site-packages\\\\torch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: include in application for MLI programme.\n",
    "personal contextual information\n",
    "I have built and trained convlutional networks in the past using keras + tensorflow.\n",
    "the inital stage of the project for me is more about re-familiarising myself with fundamentals and adapting to a new framework for underlying principles.\n",
    "'''\n",
    "\n",
    "# Define a transform to convert the data to tensor and normalize it\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the training dataset with normalization\n",
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Load the test dataset with normalization\n",
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loader for the training dataset\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create data loader for the test dataset\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize images\n",
    "def show_images(images, labels):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(10, 2))\n",
    "    for img, label, ax in zip(images, labels, axes):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Value: {label}')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a batch of images from the training data loader\n",
    "data_iter = iter(train_loader)\n",
    "pictures, true_values = next(data_iter)\n",
    "\n",
    "# Display the first 5 images\n",
    "show_images(pictures[:5], true_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrefresher on cnn fundamentals [https://www.youtube.com/watch?v=pDdP0TFzsoQ]\\nbuilding a cnn in pytorch.\\nconvolutional layers, pooling layers, rectified linear unit (ReLU) layers, and fully connected layer\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "refresher on cnn fundamentals [https://www.youtube.com/watch?v=pDdP0TFzsoQ]\n",
    "building a cnn in pytorch.\n",
    "convolutional layers, pooling layers, rectified linear unit (ReLU) layers, and fully connected layer\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables that will be used to build model and specifying processor for training\n",
    "classifications = ('0','1','2','3','4','5','6','7','8','9')\n",
    "batch_size = 64 #redeclared batch size so I can alter it for lighter load on training.\n",
    "# training_epochs = 100 #declared in 'training' section of file. here for reference\n",
    "learn_rate = 0.001\n",
    "\n",
    "#I have cuda-12.4 enabled GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)  # Should return a version number, not None\n",
    "print(torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#building conv model \n",
    "#MNIST dataset contains single-channel image -> Input 28*28\n",
    "# ( (Conv -> ReLU)*2 -> Pooling )*3 -> Fully Connected \n",
    "class ConvNet(nn.ModuleList):\n",
    "    # def __init__(self):\n",
    "        # super().__init__()\n",
    "        # self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        # self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    # def forward(self, inputs):\n",
    "    #     inputs = self.pool(F.relu(self.conv1(inputs)))\n",
    "    #     inputs = self.pool(F.relu(self.conv2(inputs)))\n",
    "    #     inputs = torch.flatten(inputs, 1) # flatten all dimensions except batch\n",
    "    #     inputs = F.relu(self.fc1(inputs))\n",
    "    #     inputs = F.relu(self.fc2(inputs))\n",
    "    #     inputs = self.fc3(inputs)\n",
    "    #     return inputs\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.view(-1, 28 * 28)  # Flatten the input\n",
    "        inputs = self.fc1(inputs)\n",
    "        inputs = self.relu(inputs)\n",
    "        inputs = self.fc2(inputs)\n",
    "        return self.softmax(inputs)\n",
    "\n",
    "\n",
    "model = ConvNet().to(device) #instance of class passed to GPU/CPU\n",
    "# model = ConvNet()\n",
    "criterion = nn.CrossEntropyLoss() #CEL for classification model\n",
    "optimiser = optim.SGD(params=model.parameters(), lr=learn_rate)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 100\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    #iterate over train set and pass into model \n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        # Get a batch of images from the training data loader\n",
    "        images = image.to(device)\n",
    "        labels = label.to(device)\n",
    "\n",
    "        outputs = model(images).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./saved_models/mid_train_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 94.300%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device) \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    # show_predictions(images.to(\"cpu\"),outputs.to(\"cpu\"),labels.to(\"cpu\"))\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test set: {accuracy:.3f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Plot some example test data with predictions and ground truths."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
